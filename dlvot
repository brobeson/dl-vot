#!/usr/bin/env python3

"""This is a script to download VOT Challenge data sets."""

import argparse
import os.path
import zipfile

import requests
import wget

__version__ = "0.0"


def _make_symlink(target, link):
    if os.path.exists(link):
        print(link, "already exists, so not creating a symlink.")
    else:
        os.symlink(target, link)


def _download_images(images_url, directory):
    zip_file = os.path.join(directory, "images.zip")
    url = METADATA_URLS[year].replace("description.json", images_url)
    wget.download(url, zip_file)
    print()
    with zipfile.ZipFile(zip_file) as file_:
        file_.extractall(path=directory)
    os.remove(zip_file)


def _download_annotations(annotations, directory):
    zip_file = os.path.join(directory, "annotations.zip")
    url = METADATA_URLS[year].replace("description.json", annotations["url"])
    wget.download(url, zip_file)
    print()
    with zipfile.ZipFile(zip_file) as file_:
        file_.extractall(path=directory)
    os.remove(zip_file)


def _make_directory_structure(sequence_name):
    sequence_directory = os.path.join(ROOT_DIRECTORY, year, sequence_name)
    images_directory = os.path.join(
        ROOT_DIRECTORY, "sequences", "color", sequence_name
    )
    os.makedirs(sequence_directory, exist_ok=True)
    os.makedirs(images_directory, exist_ok=True)
    return {"sequence": sequence_directory, "images": images_directory}


def _download_sequences(sequences):
    # for sequence in sequences:
    sequence = sequences[0]
    if "color" in sequence["channels"]:
        directories = _make_directory_structure(sequence["name"])
        print("Downloading", sequence["name"])
        _download_annotations(sequence["annotations"], directories["sequence"])
        _download_images(
            sequence["channels"]["color"]["url"], directories["images"]
        )
        _make_symlink(
            directories["images"],
            os.path.join(directories["sequence"], "color"),
        )
    else:
        print("Skipping ${sequence['name'] - It has no color channel.")


def _download_dataset_description():
    print(f"Downloading meta-data for data set {year}.")
    response = requests.get(METADATA_URLS[year])
    if response.status_code != 200:
        print(
            f"Failed to download the data set description for {year}. Here is "
            "the response text:"
        )
        print(response.reason)
    try:
        return response.json()
    except ValueError:
        print("Failed to parse the downloaded JSON content for {year}.")


def _download_dataset():
    description = _download_dataset_description()
    sequences = description["sequences"]
    _download_sequences(sequences)


def _parse_arguments():
    parser = argparse.ArgumentParser(
        description="Download VOT Challenge data sequences."
    )
    parser.add_argument(
        "--version",
        action="version",
        version=__version__,
        help="Display the version, and exit.",
    )
    parser.add_argument(
        "dataset",
        choices=["all", "2013", "2014", "2015", "2016", "2017", "2018"],
        help="The dataset(s) to download. Acceptable values are 'all', or the "
        "years 2013 through 2018. 'All' takes precedence and will download all "
        "datasets.",
        metavar="dataset",
        nargs="+",
    )
    return vars(parser.parse_args())


if __name__ == "__main__":
    ROOT_DIRECTORY = os.path.expanduser("~/Videos/vot")
    METADATA_URLS = {
        "2013": "http://data.votchallenge.net/vot2013/dataset/description.json",
        "2014": "http://data.votchallenge.net/vot2014/dataset/description.json",
        "2015": "http://data.votchallenge.net/vot2015/dataset/description.json",
        "2016": "http://data.votchallenge.net/vot2016/main/description.json",
        "2017": "http://data.votchallenge.net/vot2017/main/description.json",
        "2018": "http://data.votchallenge.net/vot2018/main/description.json",
    }
    ARGUMENTS = _parse_arguments()
    if ARGUMENTS["dataset"] == "all":
        for year in METADATA_URLS:
            _download_dataset()
    else:
        for year in ARGUMENTS["dataset"]:
            _download_dataset()
